---
title: "Phoneme surprisal"
author: Josef Klafka and Dan Yurovsky 
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show 
editor_options: 
  chunk_output_type: console
---
Briefly what we're doing is splitting each word in the corpus (Providence from CHILDES and the Switchboard corpus of adult telephone conversations) up into its constituent phones. We then calculate how common each phone is, and compute the surprisal of each phone--a measure of how much information is in the phone. 

We split up the words in the corpus by their length in number of phones. For each phone index or position in words of each length, we calculate the average information (suprisal) in the phones in that position. For example, we take all the words with four phones in the Providence corpus, and then calculate the average information in the first phone of those words, the average information in the second phone, and so on. 


```{r setup, include=FALSE}
library(tidytext)
library(tidyverse)
library(childesr)
library(glue)
library(feather)
library(here)

knitr::opts_chunk$set(echo = TRUE)
```

```{r prov phonemes}
prov_utterances <- get_utterances(corpus = "Providence") #stem or gloss

adult_utterances <- prov_utterances %>%
  filter(speaker_role != "Target_Child") %>% 
  mutate(utterance_id = 1:n()) %>% 
  unnest_tokens(word, stem, token = stringr::str_split, pattern = "[ +]|[_+]+") 

system("rm words.txt phones.txt splitphones.txt joined.csv")
adult_utterances %>%
  distinct(word) %>%
  filter(word != "", word != "tʃutʃutʃu", word != "ɛː", word != "lunchroom", word != "dryad's", word != "vi") %>%
  pull(word) %>%
  write_lines("words.txt")

system("espeak -f words.txt --ipa=3 -v en-us -q --phonout='phones.txt'") #get the ipa of each word
system("cat phones.txt | sed -E 's/ /|/g' | tr '|' '\n' | tail -n +2 > splitphones.txt") #put each ipa word onto its own line in a file called splitphones.txt
system("rm phones.txt")
system("sed '/^$/d' splitphones.txt > phones.txt") #remove empty lines in splitphones
system("paste -d , words.txt phones.txt > joined.csv") #make csv with words and their ipa paired

phones <- read.csv("joined.csv", 
                   header = F, 
                   col.names = c("word", "ipa"))

adult_phonemes <- adult_utterances %>%
  left_join(phones) %>%
  filter(!is.na(ipa)) %>%
  unnest_tokens(phone, ipa, token = stringr::str_split, pattern = "_", drop = F) %>%
  group_by(utterance_id, word) %>%
  mutate(phone_order = 1:n()) %>%
  mutate(word_length = max(phone_order)) %>%
  ungroup() %>%
  select(utterance_id, word, ipa, phone, phone_order, word_length)
  
phone_probs <- adult_phonemes %>% 
  count(phone) %>%
  ungroup() %>%
  mutate(p = n/sum(n))

ipa_unigrams <- adult_phonemes %>% 
  left_join(phone_probs) %>%
  mutate(s = -log(p)) %>%
  group_by(word_length, phone_order) %>%
  summarise(mean_s = mean(s))

ipa_unigrams %>%
  filter(word_length %in% 4:9) %>%
  ggplot(aes(x = phone_order, y = mean_s)) + 
    facet_wrap(~word_length) + 
    geom_point() +
    geom_line() + 
    xlab("Letter Position") + 
    ylab("Mean surprisal") 
```

```{r switchboard}
switchboard <- read_feather(here("../switchboard/switchboard.feather")) %>%
  mutate(utterance_id = 1:n()) %>% 
  unnest_tokens(word, value, token = stringr::str_split, pattern = "[ +]|[-+]+") 

system("rm words.txt phones.txt splitphones.txt joined.csv")
switchboard %>%
  distinct(word) %>%
  filter(word != "", word != "ii") %>%
  pull(word) %>%
  grep(pattern = "[0-9]+", value = T, invert = T) %>%
  write_lines("words.txt")

system("espeak -f words.txt --ipa=3 -v en-us -q --phonout='phones.txt'") #get the ipa of each word 
system("cat phones.txt | sed -E 's/ /|/g' | tr '|' '\n' | tail -n +2 > splitphones.txt") #put each ipa word onto its own line in a file called splitphones.txt
system("rm phones.txt")
system("sed '/^$/d' splitphones.txt > phones.txt") #remove empty lines in splitphones
system("paste -d , words.txt phones.txt > joined.csv") #make csv with words and their ipa paired

switch_phones <- read.csv("joined.csv", 
                   header = F, 
                   col.names = c("word", "ipa"))
tail(switch_phones)

adult_phonemes <- adult_utterances %>%
  left_join(phones) %>%
  filter(!is.na(ipa)) %>%
  unnest_tokens(phone, ipa, token = stringr::str_split, pattern = "_", drop = F) %>%
  group_by(utterance_id, word) %>%
  mutate(phone_order = 1:n()) %>%
  mutate(word_length = max(phone_order)) %>%
  ungroup() %>%
  select(utterance_id, word, ipa, phone, phone_order, word_length)
  
phone_probs <- adult_phonemes %>% 
  count(phone) %>%
  ungroup() %>%
  mutate(p = n/sum(n))

ipa_unigrams <- adult_phonemes %>% 
  left_join(phone_probs) %>%
  mutate(s = -log(p)) %>%
  group_by(word_length, phone_order) %>%
  summarise(mean_s = mean(s))

ipa_unigrams %>%
  filter(word_length %in% 4:9) %>%
  ggplot(aes(x = phone_order, y = mean_s)) + 
    facet_wrap(~word_length) + 
    geom_point() +
    geom_line() + 
    xlab("Letter Position") + 
    ylab("Mean surprisal")
```
