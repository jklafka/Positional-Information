---
title: "Switchboard and BNC Suprisal"
author: "Josef Klafka & Dan Yurovsky"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show 
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(directlabels)
library(tidytext)
library(tidyboot)
library(dplyr)
library(tokenizers)
library(gtools)
library(here)
library(feather)

knitr::opts_chunk$set(echo = TRUE)
```

```{r get switchboard}
switchboard <- read_feather(here("../switchboard/switchboard.feather")) %>%
  rename(text = value) %>%
  mutate(length = str_count(text, pattern = "[ +]+") + 1) %>%
  mutate(utterance_id = 1:n()) %>%
  unnest_tokens(word, text, token = stringr::str_split, pattern = "[ +]+") %>%
  group_by(utterance_id) %>%
  mutate(word_order = 1:n())
```

```{r switchboard unigrams}
switch_unigrams <- switchboard %>%
  group_by(word) %>%
  count() %>%
  ungroup() %>%
  mutate(p = n / sum(n))
  
switch_surprisals <- switchboard %>%
  left_join(switch_unigrams) %>%
  mutate(s = -log(p)) %>%
  group_by(length, word_order) %>%
  summarise(s = mean(s)) 

switch_surprisals %>%
  filter(length %in% c(3, 5, 7)) %>%
  ggplot(aes(x = word_order, y = s)) + 
  facet_wrap(~ length) + 
  geom_point() + 
  geom_smooth(se = F)
```

```{r switchboard bigrams}
switch_bigrams <- switchboard %>%
  group_by(utterance_id) %>%
  mutate(lag_word = lag(word)) %>%
  group_by(lag_word, word) %>%
  count() %>%
  filter(!is.na(lag_word)) %>%
  ungroup() %>%
  mutate(joint_p = n / sum(n)) %>%
  select(-n) %>%
  left_join(switch_unigrams, by = c("lag_word" = "word")) %>%
  mutate(cond_p = joint_p / p) %>%
  select(-n, -p)


bigram_surprisals_prep <- switchboard %>%
  group_by(utterance_id) %>%
  mutate(lag_word = lag(word)) %>%
  left_join(switch_bigrams) %>%
  left_join(switch_unigrams)


bigram_surprisals <- bigram_surprisals_prep %>%
  filter(!is.na(lag_word)) %>%
  mutate(s = -log(cond_p)) %>%
  group_by(length, word_order) %>%
  summarise(s = mean(s)) %>%
  filter(word_order <= length)

bigram_surprisals_nonnull <- bigram_surprisals_prep %>%
  mutate(s = ifelse(is.na(lag_word), -log(p), -log(cond_p))) %>%
  group_by(length, word_order) %>%
  summarise(s = mean(s)) %>% 
  filter(word_order <= length)

bigram_surprisals_nonnull %>%
  filter(length %in% c(5, 7, 9, 11, 13, 15)) %>%
  ggplot(aes(x = word_order, y = s)) + 
  facet_wrap(~ length) + 
  geom_point() + 
  geom_smooth(se = F)
```

```{r switchboard trigrams}
switch_trigrams <- switchboard %>%
  group_by(utterance_id) %>%
  mutate(lag_word1 = lag(word)) %>%
  mutate(lag_word2 = lag(lag_word1)) %>%
  group_by(lag_word2, lag_word1, word) %>%
  count() %>%
  filter(!is.na(lag_word1), !is.na(lag_word2)) %>%
  ungroup() %>%
  mutate(tri_joint_p = n / sum(n)) %>%
  select(-n) %>%
  left_join(switch_bigrams, by = c("lag_word2" = "lag_word", "lag_word1" = "word")) %>%
  mutate(tri_cond_p = tri_joint_p / joint_p) %>%
  select(-joint_p, -tri_joint_p, -cond_p) # %>% 
  # left_join(adult_bigrams, by = c("lag_word1" = "lag_word", "word" = "word")) %>% 
  # select(-joint_p) 


trigram_surprisals_prep <- switchboard %>%
  group_by(utterance_id) %>%
  mutate(lag_word1 = lag(word)) %>%
  mutate(lag_word2 = lag(lag_word1)) %>%
  left_join(switch_trigrams) %>% 
  left_join(select(switch_bigrams, -joint_p), by = c("lag_word1" = "lag_word", "word" = "word")) %>% 
  left_join(switch_unigrams)


trigram_surprisals_nonnull <- trigram_surprisals_prep %>%
  mutate(s = ifelse(is.na(lag_word2), # check if it's not the first word
                    ifelse(is.na(lag_word1), # check if not the second word
                           -log(p), # trigram if third or beyond
                           -log(cond_p)), # bigram if second word
                    -log(tri_cond_p))) %>% # unigram if first word
  group_by(length, word_order) %>%
  summarise(s = mean(s)) %>% 
  filter(word_order <= length)

trigram_surprisals_nonnull %>%
  filter(length %in% c(5, 7, 9, 11, 13, 15)) %>%
  ggplot(aes(x = word_order, y = s)) + 
  facet_wrap(~ length) + 
  geom_point() + 
  geom_smooth(se = F)
```

A pre-requisite for the next section is that you run the "process_bnc.Rmd" pipeline for preprocessing the British National Corpus (bnc). The files are too large to store in the GitHub repository. 

```{r bnc}
bnc <- read_feather(here("../bnc/bnc10.feather")) %>%
  bind_rows(read_feather(here("../bnc/bnc20.feather"))) %>%
  bind_rows(read_feather(here("../bnc/bnc30.feather")))
```

```{r bnc unigrams}
bnc_unigrams <- bnc %>%
  group_by(word) %>%
  count() %>%
  ungroup() %>%
  mutate(p = n / sum(n))
  
bnc_surprisals <- bnc %>%
  left_join(bnc_unigrams) %>%
  mutate(s = -log(p)) %>%
  group_by(length, word_order) %>%
  summarise(s = mean(s)) 

bnc_surprisals %>%
  ggplot(aes(x = word_order, y = s)) + 
  facet_wrap(~ length) + 
  geom_point() + 
  geom_smooth(se = F)
```

```{r bnc bigrams}
bnc_bigrams <- bnc %>%
  group_by(utterance_id) %>%
  mutate(lag_word = lag(word)) %>%
  group_by(lag_word, word) %>%
  count() %>%
  filter(!is.na(lag_word)) %>%
  ungroup() %>%
  mutate(joint_p = n / sum(n)) %>%
  select(-n) %>%
  left_join(bnc_unigrams, by = c("lag_word" = "word")) %>%
  mutate(cond_p = joint_p / p) %>%
  select(-n, -p)


bigram_surprisals_prep <- bnc %>%
  group_by(utterance_id) %>%
  mutate(lag_word = lag(word)) %>%
  left_join(bnc_bigrams) %>%
  left_join(bnc_unigrams)


bigram_surprisals <- bigram_surprisals_prep %>%
  filter(!is.na(lag_word)) %>%
  mutate(s = -log(cond_p)) %>%
  group_by(length, word_order) %>%
  summarise(s = mean(s)) %>%
  filter(word_order <= length)

bigram_surprisals_nonnull <- bigram_surprisals_prep %>%
  mutate(s = ifelse(is.na(lag_word), -log(p), -log(cond_p))) %>%
  group_by(length, word_order) %>%
  summarise(s = mean(s)) %>% 
  filter(word_order <= length)

bigram_surprisals_nonnull %>%
  ggplot(aes(x = word_order, y = s)) + 
  facet_wrap(~ length) + 
  geom_point() + 
  geom_smooth(se = F)
```

```{r bnc trigrams}
bnc_trigrams <- bnc %>%
  group_by(utterance_id) %>%
  mutate(lag_word1 = lag(word)) %>%
  mutate(lag_word2 = lag(lag_word1)) %>%
  group_by(lag_word2, lag_word1, word) %>%
  count() %>%
  filter(!is.na(lag_word1), !is.na(lag_word2)) %>%
  ungroup() %>%
  mutate(tri_joint_p = n / sum(n)) %>%
  select(-n) %>%
  left_join(bnc_bigrams, by = c("lag_word2" = "lag_word", "lag_word1" = "word")) %>%
  mutate(tri_cond_p = tri_joint_p / joint_p) %>%
  select(-joint_p, -tri_joint_p, -cond_p) # %>% 


trigram_surprisals_prep <- bnc %>%
  group_by(utterance_id) %>%
  mutate(lag_word1 = lag(word)) %>%
  mutate(lag_word2 = lag(lag_word1)) %>%
  left_join(bnc_trigrams) %>% 
  left_join(select(bnc_bigrams, -joint_p), by = c("lag_word1" = "lag_word", "word" = "word")) %>% 
  left_join(bnc_unigrams)


trigram_surprisals_nonnull <- trigram_surprisals_prep %>%
  mutate(s = ifelse(is.na(lag_word2), # check if it's not the first word
                    ifelse(is.na(lag_word1), # check if not the second word
                           -log(p), # trigram if third or beyond
                           -log(cond_p)), # bigram if second word
                    -log(tri_cond_p))) %>% # unigram if first word
  group_by(length, word_order) %>%
  summarise(s = mean(s)) %>% 
  filter(word_order <= length)

trigram_surprisals_nonnull %>%
  ggplot(aes(x = word_order, y = s)) + 
  facet_wrap(~ length) + 
  geom_point() + 
  geom_smooth(se = F)
```