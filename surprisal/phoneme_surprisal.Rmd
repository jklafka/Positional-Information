---
title: "Phoneme surprisal"
author: Josef Klafka and Dan Yurovsky 
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show 
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
library(tidytext)
library(tidyverse)
library(childesr)
library(glue)

knitr::opts_chunk$set(echo = TRUE)
```

```{r espeak pipeline}
get_ipa <- function(word) {
  system2("espeak", args = c("--ipa=3", "-v", "en-us", "-q", glue('"{word}"')),
          stdout = TRUE) %>%
    gsub("^ ", "", .) %>%
    gsub("[ˈˌ]", "", .)
}
```

```{r phonemes}
prov_utterances <- get_utterances(corpus = "Providence") #stem or gloss

adult_utterances <- prov_utterances %>%
  filter(speaker_role != "Target_Child") %>% 
  mutate(utterance_id = 1:n()) %>% 
  unnest_tokens(word, stem, token = stringr::str_split, pattern = "[ +]|[_+]+") 

system("rm words.txt phones.txt splitphones.txt joined.csv")
adult_utterances %>%
  distinct(word) %>%
  filter(word != "", word != "tʃutʃutʃu", word != "ɛː", word != "ˈɛ_s") %>%
  # rowwise() %>%
  # mutate(ipa = get_ipa(word)) 
  pull(word) %>%
  write_lines("words.txt")

system("espeak -f words.txt --ipa=3 -v en-us -q --phonout='phones.txt'") #get the ipa of each word
system("cat phones.txt | sed -E 's/ /|/g' | tr '|' '\n' | tail -n +2 > splitphones.txt") #put each ipa word onto its own line in a file called splitphones.txt
system("rm phones.txt")
system("sed '/^$/d' splitphones.txt > phones.txt") #remove empty lines in splitphones
system("paste -d , words.txt phones.txt > joined.csv") #make csv with words and their ipa paired


phones <- read.csv("joined.csv", 
                   header = F, 
                   col.names = c("words", "ipa"))
# phones <- read_lines("joined.txt") %>%
#   str_split(" ", simplify = F) %>%
#   unlist() %>%
#   unlist() %>%
#   enframe(name = NULL) %>%
#   filter(nchar(value) > 0)

adult_phonemes <- adult_utterances %>%
  left_join(phones) %>%
  unnest_tokens(ipa, word, token = stringr::str_split, pattern = "_", drop = F) %>%
  group_by(utterance_id, word) %>%
  mutate(ipa_order = 1:n()) %>%
  mutate(word_length = max(ipa_order)) %>%
  ungroup()
  
ipa_probs <- adult_phonemes %>% 
  count(ipa) %>%
  ungroup() %>%
  mutate(p = n/sum(n))

ipa_unigrams <- adult_utterances %>% 
  left_join(ipa_probs) %>%
  mutate(s = -log(p)) %>%
  group_by(word_length, ipa_order) %>%
  summarise(mean_s = mean(s))



ipa_unigrams %>%
  filter(word_length %in% 3:11) %>%
  ggplot(aes(x = ipa_order, y = mean_s)) + 
    facet_wrap(~word_length) + 
    geom_point() +
    geom_line() + 
    xlab("Letter Position") + 
    ylab("Mean surprisal")
```


```{r providence}
prov_utterances <- get_utterances(corpus = "Providence") #stem or gloss

child_utterances <- prov_utterances %>%
  filter(speaker_role == "Target_Child") %>% 
  mutate(length = str_count(gloss, pattern = "[ +]+") + 1) %>%
  mutate(utterance_id = 1:n()) %>%
  unnest_tokens(word, gloss, token = stringr::str_split, pattern = "[ +]+") %>%
  group_by(utterance_id) %>%
  mutate(word_order = 1:n()) %>%
  mutate(ipa = get_ipa(word, "en-us"))


```
