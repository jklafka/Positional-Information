---
title: "Wikipedia WALS Feature Analysis"
author: "Josef Klafka and Dan Yurovsky"
date: "7/9/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(lingtypology)
library(feather)
library(here)
library(missMDA)
library(lsa)
library(reshape2)
library(broom)
knitr::opts_chunk$set(echo = TRUE)
```

```{r read in data}
wals <- read_csv(here("Data/wals_isos.csv"))

feature_names <- read_feather(here("Wikipedia/feature_names.feather"))
clean_names <- feature_names %>% mutate(feature = make_clean_names(feature))

wiki <- read_csv(here("Data/relative_ngrams.csv"))
LANGUAGES <- wiki %>% pull(language) %>% unique()
```

```{r see which WALS features are the most complete for our languages}
all_languages <- wals %>% 
  filter(rowSums(is.na(.)) < 130) %>%
  group_by(language) %>%
  slice(1) %>%
  ungroup() 
```

```{r get common languages between the imputations and models}
nom_categories <- all_languages %>%
  select(language, x30a:x57a) %>%
  filter(rowSums(is.na(.)) < 12)

nom_syntax <- all_languages %>%
  select(language, x58a:x64a) %>%
  filter(rowSums(is.na(.)) < 5)

verb_categories <- all_languages %>%
  select(language, x65a:x80a) %>%
  filter(rowSums(is.na(.)) < 8)

word_order <- all_languages %>%
  select(language, x81a:x97a) 

clauses <- all_languages %>%
  select(language, x98a:x121a) %>%
  filter(rowSums(is.na(.)) < 12)

common_df <- nom_categories %>%
  inner_join(nom_syntax) %>%
  inner_join(verb_categories) %>%
  inner_join(word_order) %>%
  inner_join(clauses)

common_languages <- common_df %>%
  pull(language)
```

```{r feature space}
imputed_df <- read_csv(here("Data/imputed_wals.csv"))

feature_space <- imputed_df %>% 
  gather(feature, value, -language) %>% 
  group_by(feature) %>% 
  mutate(value = as.numeric(as.factor(value))) %>% 
  spread(feature, value) %>%
  column_to_rownames("language") %>%
  dist(method = "manhattan") %>%
  as.matrix() %>%
  melt(value.name = "feature") %>%
  as_tibble() %>%
  rename(language1 = Var1, language2 = Var2) 
```

```{r cosines}
unigram_cosines <- wiki %>%
  filter(language %in% common_languages, gram == "Unigram") %>%
  select(-gram) %>% 
  column_to_rownames("language") %>%
  t() %>%
  cosine() %>%
  as_data_frame(rownames = "language1") %>%
  gather(language2, unigram_cosine, -language1) %>%
  mutate(unigram_cosine = 1 - abs(unigram_cosine)) 

bigram_cosines <- wiki %>%
  filter(language %in% common_languages, gram == "Bigram") %>%
  select(-gram) %>% 
  column_to_rownames("language") %>%
  t() %>%
  cosine() %>%
  as_data_frame(rownames = "language1") %>%
  gather(language2, bigram_cosine, -language1) %>%
  mutate(bigram_cosine = 1 - abs(bigram_cosine)) 

trigram_cosines <- wiki %>%
  filter(language %in% common_languages, gram == "Trigram") %>%
  select(-gram) %>% 
  column_to_rownames("language") %>%
  t() %>%
  cosine() %>%
  as_data_frame(rownames = "language1") %>%
  gather(language2, trigram_cosine, -language1) %>%
  mutate(trigram_cosine = 1 - abs(trigram_cosine)) 

all_distances <- feature_space %>%
  left_join(unigram_cosines) %>%
  left_join(bigram_cosines) %>%
  left_join(trigram_cosines)

all_distances %>% 
  ggplot(aes(x = feature)) +
    geom_smooth(aes(y = unigram_cosine, color = "#0033CC"), 
                method = 'lm', se = F) + 
    geom_smooth(aes(y = bigram_cosine, color = "#6699FF"), 
                method = 'lm', se = F) +
    geom_smooth(aes(y = trigram_cosine, color = "#33CCFF"), 
                method = 'lm', se = F) +
    geom_point(aes(y = unigram_cosine, color = "#0033CC")) + 
    geom_point(aes(y = bigram_cosine, color = "#6699FF")) + 
    geom_point(aes(y = trigram_cosine, color = "#33CCFF")) + 
    ylab("Cosine Space Distance") + 
    xlab("Feature Space Distance") + 
    scale_color_manual(name = "Gram", 
                       values = c("#0033CC", "#6699FF", "#33CCFF"), 
                       labels = c("Unigrams", "Bigrams", "Trigrams")) + 
    ggtitle("Cosine space distance regressed on feature spaced distance")
```

```{r models}
imputed_df <- read_csv(here("Data/imputed_wals.csv"))

wf_sub <- imputed_df %>% 
  group_by(language) %>%
  slice(1) %>%
  gather(feature, value, -language) %>%
  group_by(feature) %>%
  mutate(value = as.numeric(as.factor(value)))

cosines <- wiki %>%
  filter(language %in% common_languages, gram == "Unigram") %>%
  select(-gram) %>% 
  column_to_rownames("language") %>%
  t() %>%
  cosine() %>%
  as_data_frame(rownames = "language1") %>%
  gather(language2, cosine, -language1)

wf_pairwise <- expand.grid(language1 = wf_sub$language,
                           language2 = wf_sub$language) %>%
  left_join(wf_sub, by = c("language1" = "language")) %>%
  rename(value1 = value) %>%
  left_join(wf_sub, by = c("language2" = "language", "feature")) %>%
  rename(value2 = value) %>%
  mutate(same = value1 == value2) %>%
  select(-value1, -value2) %>%
  left_join(cosines, by = c("language1", "language2"))

models <- wf_pairwise %>%
  group_by(feature) %>%
  nest() %>%
  mutate(model = map(data, ~glm(same ~ cosine, 
                                family = "binomial", data = .)))


model_df <- models %>%
  mutate(coeffs = map(model, tidy)) %>%
  select(-data, -model) %>%
  unnest() %>%
  filter(term == "cosine") %>%
  arrange(desc(statistic)) %>%
  left_join(clean_names, by = "feature")
```

```{r imputation}
imputed_df <- common_df %>% 
  gather(feature, value, -language) %>%
  group_by(feature) %>%
  mutate(value = factor(value)) %>%
  select(language, feature, value) %>%
  ungroup() %>% 
  spread(feature, value) %>% 
  sapply(as.factor) %>%
  as.data.frame() %>%
  column_to_rownames("language") %>% 
  MIMCA(ncp = 1)

imputed_df <- as.data.frame(imputed_df[[1]][[99]]) 
```

## Errata

```{r cleaning}
wiki <- read_feather(here("Data/relative_ngrams.feather"))
wiki %>% 
  group_by(language) %>% 
  mutate(order = 1:n()) %>% 
  ungroup() %>% 
  filter(order <= 15) %>% 
  select(-order) %>%
  select(language, gram, estimate, cut) %>% 
  spread(cut, estimate) %>% 
  rename(Slope1 =`1`, Slope2 =`2`, Slope3 =`3`, Slope4 =`4`, Slope5 =`5`) %>%
  write_csv(here("Data/relative_ngrams.csv"))
```
