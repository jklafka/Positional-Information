---
title: "Linguistic distance"
author: "Josef Klafka and Dan Yurovsky"
date: "8/9/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(stringdist)
library(lsa)
library(feather)

knitr::opts_chunk$set(echo = TRUE)
```

```{r read in data}
wals <- read_csv(here("Data/imputed_all.csv"))
wiki <- read_csv(here("Data/relative_ngrams.csv"))
iso_to_language <- read_csv(here("Data/wiki_wals.csv")) %>%
  select(language, iso) %>%
  group_by(language) %>%
  slice(1) %>% 
  ungroup()

asjp_forms <- read_csv(here("asjp_dataset/forms.csv"))
asjp_langs <- read_csv(here("asjp_dataset/languages.csv"))
lang_forms <- asjp_forms %>% 
  select(Language_ID, Parameter_ID, Form) %>% 
  left_join(asjp_langs %>% select(ID, ISO639P3code), by = c("Language_ID" = "ID")) %>%
  left_join(iso_to_language, by = c("ISO639P3code" = "iso")) %>%
  filter(complete.cases(.)) %>% 
  select(language, Parameter_ID, Form) %>%
  group_by(language, Parameter_ID) %>% ## taking off one at random for each language - fix
  slice(1) %>%
  ungroup() 

langs <- wals %>% pull(language)
```

```{r make swadesh space}
langs_pairwise <- expand.grid(language1 = langs,
                           language2 = langs) %>%
  filter(language1 != language2)

asjp_distance <- function(language1, language2) {
  lang_forms %>% 
    filter(language == language1) %>%
    left_join(lang_forms %>% filter(language == language2), by = "Parameter_ID") %>% 
    filter(complete.cases(.)) %>% 
    mutate(ldn = stringdist(Form.x, Form.y) / max(str_length(c(Form.x, Form.y)))) %>%
    group_by(language.x, language.y) %>% 
    summarise(ldn = mean(ldn)) %>% 
    rename(language1 = language.x, language2 = language.y) %>% 
    ungroup()
}

swadesh_space <- map_dfr(1:nrow(langs_pairwise), ~asjp_distance(langs_pairwise[.x,"language1"],
                                          langs_pairwise[.x,"language2"])) 
```

```{r compare swadesh and information curve spaces}
all_distances <- read_feather(here("Data/all_spaces.feather"))

all_distances %>% 
  ggplot(aes(x = ldn)) +
    geom_smooth(aes(y = unigram_cosine, color = "#0033CC"), 
                method = 'lm', se = F) + 
    # geom_smooth(aes(y = bigram_cosine, color = "#6699FF"), 
    #             method = 'lm', se = F) +
    geom_smooth(aes(y = trigram_cosine, color = "#33CCFF"), 
                method = 'lm', se = F) +
    geom_hex(aes(y = unigram_cosine, color = "#0033CC", alpha=.2)) + 
    # geom_point(aes(y = bigram_cosine, color = "#6699FF")) + 
    geom_hex(aes(y = trigram_cosine, color = "#33CCFF", alpha=.2)) + 
    ylab("Information Curve Cosine") + 
    xlab("Average Swadesh Distance") + 
    scale_color_manual(name = "Gram", 
                       values = c("#0033CC", "#33CCFF"), 
                       labels = c("Unigrams", "Trigrams")) 
```

## Making the data

```{r pairing up spaces}
unigram_cosines <- wiki %>%
  filter(language %in% langs, gram == "Unigram") %>%
  select(-gram) %>% 
  column_to_rownames("language") %>%
  t() %>%
  cosine() %>%
  as_data_frame(rownames = "language1") %>%
  gather(language2, unigram_cosine, -language1) 

trigram_cosines <- wiki %>%
  filter(language %in% langs, gram == "Trigram") %>%
  select(-gram) %>% 
  column_to_rownames("language") %>%
  t() %>%
  cosine() %>%
  as_data_frame(rownames = "language1") %>%
  gather(language2, trigram_cosine, -language1)

feature_space <- read_feather(here("Data/feature_cosine_spaces.feather")) %>% 
  select(language1, language2, feature)

all_distances <- swadesh_space %>%
  left_join(unigram_cosines) %>%
  left_join(trigram_cosines) %>% 
  left_join(feature_space)

all_distances %>% write_feather(here("Data/all_spaces.feather"))
```
