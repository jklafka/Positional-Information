---
title: Wikipedia Text Mining and Entropy Analysis
author: Josef Klafka and Dan Yurovsky
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show 
---

```{r setup, include=FALSE}
library(tidyverse)
library(googlesheets)
library(lingtypology)
library(knitr)
library(klaR)
library(missMDA)
library(clusteval)
library(factoextra)
library(cluster)

knitr::opts_chunk$set(echo = TRUE)

opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
               error = FALSE, cache = FALSE, tidy = FALSE)

theme_set(theme_classic(base_size = 16))
```

```{r clustering}
K <- 10 ## number of clusters

##read in googlesheet
wiki_gs <- gs_title("Wikipedia_absolute")
wkpd <- gs_read(wiki_gs) 
LANGUAGES <- wkpd$Language

wkpd <- wkpd %>% 
  as.data.frame() %>%
  column_to_rownames(var = "Language")

##do clustering
wk_clust <- wkpd %>% 
              dist() %>%
              hclust("ward.D2")

wk_clust %>% plot(hang = -1)
```

```{r MCA_imputation}
wiki_gs <- gs_title("Wikipedia_absolute")
wkpd <- gs_read(wiki_gs) 
LANGUAGES <- wkpd$Language

FEATURES <- c(1:144)
for (i in c(1:144)) {
  FEATURES[i] <- paste(FEATURES[i], "A", sep = "")
} #get all WALS features in correct syntax

wf <- wals.feature(FEATURES)
wf.sub <- wf[c("1A", "2A", "3A", "4A", "language")]
wf.sub <- wf.sub %>% 
  filter(language %in% LANGUAGES) %>%
  unique()

for (i in 1:4) {
  wf.sub[, i] <- factor(wf.sub[, i])
}

wf.sub <- wf.sub[rowSums(is.na(wf.sub)) != 4, ]
rownames(wf.sub) <- wf.sub$language
wf.sub$language <- NULL
rv <- MIMCA(wf.sub, ncp = 4)

imputed_wf <- as.data.frame(rv[[1]][[99]])
```

```{r Gelman}
## from http://www.stat.columbia.edu/~gelman/bda/regression.R

sigma.hat <- function (object){
  object.class <- class(object)[[1]]
  if (object.class=="lm"){
    sigma <- summary(object)$sigma
    return (sigma)
  }
  else if (object.class=="glm"){
    sigma <- summary(object, correlation=TRUE)$sigma
    return (sigma)
  }
  else if (object.class=="lmer"){
    object <- summary (object)
    fcoef <- .Call("mer_fixef", object, PACKAGE = "lme4")
    useScale <- object@devComp[8]
    ngrps <- lapply(object@flist, function(x) length(levels(x)))
    n.groupings <- length (ngrps)
    varc <- VarCorr (object, useScale=useScale)
    sc <- attr(varc, "sc")
    recorr <- lapply(varc, function(el) el@factors$correlation)
    reStdDev <- c(lapply(recorr, slot, "sd"), list(Residual = sc))
    sigmas <- as.list (rep (NA, n.groupings+1))
    sigmas[1] <- ifelse (useScale, sc, NA)
    cors <- as.list (rep (NA, n.groupings+1))
    names (sigmas) <- names (cors) <- c ("data", names (varc))
    for (k in 1:n.groupings){
      sigmas[[k+1]] <- reStdDev[[k]]
      cors[[k+1]] <- as.matrix (recorr[[k]])
      if (length (cors[[k+1]]) == 1) cors[[k+1]] <- NA
    }
    return (list (sigma=sigmas, cors=cors))
  }
}
```

```{r WALS_imputation_functions}
#taken from https://www.tutorialspoint.com/r/r_mean_median_mode.htm
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

## imputation based on Gelman & Hill Chapter 25
random.imp <- function(a) {
  missed <- is.na(a)
  num_missed <- sum(missed)
  a.obs <- a[!missed]
  imputed <- a
  imputed[missed] <- base::sample(a.obs, num_missed, replace=TRUE)
  return(imputed)
}

impute <- function(a, a.impute) {
  ifelse(is.na(a), a.impute, a)
}

get_factor <- function(cname) {
  a.imp <- wf.sub[c(cname)] %>%
    random.imp() %>%
    unlist(use.names = FALSE)
}
```


```{r WALS_imputation_code}
FEATURES <- c(1:144)
for (i in c(1:144)) {
  FEATURES[i] <- paste(FEATURES[i], "A", sep = "")
} #get all WALS features in correct syntax

NUM_CLUSTERS <- 4

wf <- wals.feature(FEATURES)
wf.sub <- wf[c("1A", "2A", "3A", "4A", "language")]
wf.sub <- wf.sub %>% 
  filter(language %in% LANGUAGES) %>%
  unique()

for (i in 1:4) {
  wf.sub[, i] <- factor(wf.sub[, i])
}

a1.imp <- get_factor("1A")
a2.imp <- get_factor("2A")
a3.imp <- get_factor("3A")
a4.imp <- get_factor("4A")

a1.mode <- getmode(wf.sub$`1A`[!is.na(wf.sub$`1A`)]) #gets the most common non-na value of column 1A

n.sims <- 10
for (s in 1:n.sims) {
  a1 <- wf.sub$`1A`
  a1[is.na(a1)] <- getmode(a1[!is.na(a1)])
  lm.1 <- glm(a1 ~ a2.imp + a3.imp + a4.imp, family = "binomial")
  pred.1 <- rnorm(n, predict(lm.1), sigma.hat(lm.1)) ####
  a1.imp <- impute(wf.sub[c("1A")], pred.1)
}

```

```{r WALS_clustering}
FEATURES <- c(1:144)
for (i in c(1:144)) {
  FEATURES[i] <- paste(FEATURES[i], "A", sep = "")
} #get all WALS features in correct syntax

NUM_CLUSTERS <- 4

wf <- wals.feature(FEATURES)
wf %>% View()
wf <- wf[, -(1:3)]
wf <- wf[, -(ncol(wf) - 1)]
wf <- wf %>% 
  filter(language %in% LANGUAGES)
wf <- wf[, complete.cases(wf)] #this significantly trims down the dataset but is necessary for k-modes
rv <- kmodes(wf[, -(ncol(wf))], NUM_CLUSTERS, iter.max=10, weighted = FALSE)

```
