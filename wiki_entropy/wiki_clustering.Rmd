---
title: Wikipedia Text Mining and Entropy Analysis
author: Josef Klafka and Dan Yurovsky
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show 
---

```{r setup, include=FALSE}
library(tidyverse)
library(googlesheets)
library(lingtypology)
library(knitr)
library(missMDA)
library(cluster)
library(widyr)
library(lsa)
library(magrittr)

knitr::opts_chunk$set(echo = TRUE)

opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
               error = FALSE, cache = FALSE, tidy = FALSE)

theme_set(theme_classic(base_size = 16))
```

```{r clustering}
NUM_CLUSTERS <- 10

##read in googlesheet
wiki_gs <- gs_title("Wikipedia_absolute")
wkpd <- gs_read(wiki_gs) 
LANGUAGES <- wkpd$Language

wkpd <- wkpd %>% 
  as.data.frame() %>%
  column_to_rownames(var = "Language")

##do clustering
wk_clust_tree <- wkpd %>% 
              dist() %>%
              hclust("ward.D2") 

wk_clust_tree %>% plot(hang = -1)
wk_clusters <- wk_clust_tree %>%
              cutree(k = NUM_CLUSTERS)


wk_clusters %>% 
  t() %>%
  as_data_frame() %>% 
  t() %>%
  as_data_frame(rownames = "language") %>%
  rename(cluster = V1) %>%
  arrange(cluster) %>% 
  View()
```

```{r MCA_imputation}
wiki_gs <- gs_title("Wikipedia_absolute")
wkpd <- gs_read(wiki_gs) 
LANGUAGES <- wkpd$Language

FEATURES <- c(1:144)
for (i in c(1:144)) {
  FEATURES[i] <- paste(FEATURES[i], "A", sep = "")
} #get all WALS features in correct syntax

wf <- wals.feature(FEATURES)

wf_df <- wf %>%
  as_data_frame() %>%
  filter(language %in% LANGUAGES) %>%
  group_by(language) %>%
  slice(1) %>%
  gather(feature, value, `1A`:`144A`) %>%
  group_by(feature) %>%
  mutate(value = factor(value))

for (i in 1:4) {
  wf.sub[, i] <- factor(wf.sub[, i])
}

wf.sub <- wf.sub[rowSums(is.na(wf.sub)) != 4, ]
rownames(wf.sub) <- wf.sub$language
wf.sub$language <- NULL
rv <- MIMCA(wf.sub, ncp = 4)

imputed_wf <- as.data.frame(rv[[1]][[99]])

wals_clust_full <- kmodes(imputed_wf, NUM_CLUSTERS, iter.max=10, weighted = FALSE)
```

```{r}

wf_many_langs <- wf_df %>%
  group_by(feature) %>%
  summarise(n = sum(!is.na(value))) %>%
  filter(n > 60)

wf_sub_langs <- wf_df %>%
  filter(feature %in% wf_many_langs$feature) %>%
  group_by(language) %>%
  summarise(keep = sum(is.na(value)) == 0) %>%
  filter(keep)

wf_sub <- wf_df %>%
  filter(feature %in% wf_many_langs$feature,
         language %in% wf_sub_langs$language) %>%
  dplyr::select(language, feature, value) %>%
  group_by(feature) %>%
  mutate(value = as.numeric(as.factor(value))) %>%
  group_by(feature) %>% # for each pair of language, does this feature assin them the same value
  nest() #maps features to a table mapping languages to numerical factor feature values
  # mutate(cors = map(data, my_pairwise_cor))
  # select(-data) %>%
  # unnest()

wf_comp <- wf_sub %$%
  data %>%
  do.call(cbind, args=.) 

wf_comp <- wf_comp[, -seq(3, length(wf_comp), 2)] 
langs_to_compare <- wf_comp$language
wf_comp %<>% 
  as.data.frame(row.names=wf_comp$language) 

wkpd_comp <- wkpd %>%
    filter(Language %in% langs_to_compare) 
wkpd_comp %<>% as.data.frame(row.names=wkpd_comp$Language)

lang_pairs <- langs_to_compare %>%
  combn(2, simplify = FALSE) 

K <- length(lang_pairs)
  
lang_x <- lang_pairs %>%
    unlist() %>%
    matrix(nrow = K, byrow=TRUE) %>%
    as.data.frame() %>%
    mutate(wiki = lsa::cosine(wkpd_comp[V1, ], wkpd_comp[V2, ]), 
           wals = lsa::cosine(wf_comp[V1, ], wf_comp[V2, ]))


```

```{r evaluate_clusters}
wals_clusters <- wals_clust["cluster"] %>% unlist(use.names= FALSE)
```
