---
title: Unigram entropy in childes
author: Joe Klafka
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show 
---

```{r setup, include = FALSE}
# load packages
library(knitr)
library(tidyverse)
library(directlabels)
library(childesr) #data
library(SnowballC) #stemmer
library(tidytext)
library(entropy)
library(tidyboot)
library(dplyr)
library(tokenizers)
library(tau)
library(reticulate)
knitr::opts_chunk$set(echo = TRUE)

opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
               error = FALSE, cache = FALSE, tidy = FALSE)

theme_set(theme_classic(base_size = 16))
```

Get utterances
```{r get_utterances}
prov_utterances <- get_utterances(corpus = "Providence")
```

Compute Providence Corpus Estimates
```{r calc_pos_entropy}
get_entropies <- function(role, sen_length, utterances) {
  
  if(role == "Target_Child") {
    sub_utterances <- utterances %>%
      filter(speaker_role == "Target_Child") %>%
      mutate(length = str_count(stem, " ") + 1) # uses stems of words, not original words
  } else {
     sub_utterances <- utterances %>%
      filter(speaker_role != "Target_Child") %>%
      mutate(length = str_count(stem, " ") + 1)
  }
  
  # 
  # 
  # ggplot(adult_utterances, aes(x = length)) +
  #   geom_histogram(fill = "white", color = "black")
  
  tokens <- sub_utterances %>%
    filter(length == sen_length) %>%
    mutate(utterance_id = 1:n()) %>%
    unnest_tokens(word, stem) %>%
    group_by(utterance_id) %>%
    mutate(word_order = 1:n())
   
  tokens %>%
    group_by(word_order, word) %>%
    summarise(n = n()) %>%
    tidyboot(summary_function = function(x) x %>% 
               summarise(entropy = entropy(n, unit = "log2")),
             statistics_functions = function(x) x %>%
             summarise_at(vars(entropy), funs(ci_upper, ci_lower))) %>%
    mutate(role = role, length = sen_length)
}

entropies <- map(2:10, ~get_entropies("not child", .x, prov_utterances)) %>%
  bind_rows()

ggplot(entropies, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F)



entropies_child <- map(2:10, ~ get_entropies("Target_Child", .x, prov_utterances)) %>%
  bind_rows()

ggplot(entropies_child, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F)

entropies_all <- bind_rows(entropies, entropies_child)

ggplot(entropies_all, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper, color = role)) +
  facet_wrap(~ length) + 
  geom_pointrange(position = position_dodge(.25)) +
  geom_smooth(se = F) +
  ggtitle("Child and Adult Positional Entropy vs. Word Position (Providence corpus)")


new_utterances <- prov_utterances %>% filter(speaker_role=="Target_Child") %>% mutate(len = str_count(stem, " ") + 1)
#toks <- new_utterances %>% 

ggplot(new_utterances, aes(x=len)) +
  geom_histogram(binwidth = 1)
```

Compile all bigrams in corpus (save for another time) 
```{r ngram_frequencies}
m_prov <- prov_utterances %>%
          filter(speaker_role == "Target_Child") %>%
          mutate(length = str_count(stem, " ") + 1) %>% 
          filter(length >= 2)


b_prov <- m_prov %>% mutate(bigrams = paste(unlist(textcnt(stem, n = 2, split = " ", method = "string")), collapse = ",")) #get all the counts of bigrams from all of the dataframe
counts <- b_prov$bigrams[1] %>% strsplit(split=',') %>% unlist() %>% as.numeric()
fileConn <- file("bigram_counts.txt")
writeLines(b_prov$bigrams[1], fileConn)
close(fileConn)

b_prov <- m_prov %>% mutate(bigrams = paste(unlist(names(textcnt(stem, n = 2, split = " ", method = "string"))), collapse = ",")) #get all of the bigrams from the entire dataframe
bigrams <- b_prov$bigrams[1] %>% strsplit(split=',') %>% unlist()
fileConn <- file("bigram_words.txt")
writeLines(b_prov$bigrams[1], fileConn)
close(fileConn)
```

Non-English Unigram frequencies
```{r Spanish unigram frequencies}
shiro_utterances <- get_utterances(language = "SPA", corpus="Shiro") 
#Venezuelan children narrative (113 children; half 1st graders half 4th graders; half high SES half low SES)

okayama_utterances <- get_utterances(corpus = "Okayama") #mother-child conversations in the Osaka area

get_noneng_entropies <- function(role, sen_length, utterances, lang) {
  
  if(role == "Target_Child") {
    sub_utterances <- utterances %>%
      filter(speaker_role == "Target_Child") %>%
      mutate(stems = wordStem(gloss, language = lang)) %>% 
      mutate(length = str_count(stems, " ") + 1) 
  } else {
     sub_utterances <- utterances %>%
      filter(speaker_role != "Target_Child") %>%
      mutate(stems = wordStem(gloss, language = lang)) %>% 
      mutate(length = str_count(stems, " ") + 1)
  }
  
  # 
  # 
  # ggplot(adult_utterances, aes(x = length)) +
  #   geom_histogram(fill = "white", color = "black")
  
  tokens <- sub_utterances %>%
    filter(length == sen_length) %>%
    mutate(utterance_id = 1:n()) %>%
    unnest_tokens(word, stems) %>%
    group_by(utterance_id) %>%
    mutate(word_order = 1:n())
   
  tokens %>%
    group_by(word_order, word) %>%
    summarise(n = n()) %>%
    tidyboot(summary_function = function(x) x %>% 
               summarise(entropy = entropy.empirical(n, unit = "log2")),
             statistics_functions = function(x) x %>%
             summarise_at(vars(entropy), funs(ci_upper, ci_lower))) %>%
    mutate(role = role, length = sen_length)
}

entropies <- map(2:10, ~get_noneng_entropies("not child", .x, shiro_utterances, "spanish")) %>%
  bind_rows() %>% filter(word_order <= length) #some utterances have ""

ggplot(entropies, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Adult Unigram Entropy vs. Word Position (Spanish Shiro Corpus with stemming)")


entropies_child <- map(2:10, ~ get_noneng_entropies("Target_Child", .x, shiro_utterances, "spanish")) %>%
  bind_rows() %>% filter(word_order <= length)

ggplot(entropies_child, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Child Unigram Entropy vs. Word Position (Spanish Shiro Corpus with stemming)")

entropies_all <- bind_rows(entropies, entropies_child)

ggplot(entropies_all, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper, color = role)) +
  facet_wrap(~ length) + 
  geom_pointrange(position = position_dodge(.25)) +
  geom_smooth(se = F) +
  ggtitle("Adult and Child Unigram Entropy vs. Word Position (Spanish Shiro Corpus with stemming)")
```

```{r German Unigram Frequencies}
wagner_utterances <- get_utterances(corpus = "Wagner") #German corpus of children during daily routines (age range from 1,5 to 14,10)

entropies <- map(2:10, ~get_noneng_entropies("not child", .x, wagner_utterances, "german")) %>%
  bind_rows() %>% filter(word_order <= length) #some utterances have ""

ggplot(entropies, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Adult Unigram Entropy vs. Word Position (German Wagner Corpus with stemming)")


entropies_child <- map(2:10, ~ get_noneng_entropies("Target_Child", .x, wagner_utterances, "german")) %>%
  bind_rows() %>% filter(word_order <= length)

ggplot(entropies_child, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Child Unigram Entropy vs. Word Position (German Wagner Corpus with stemming)")

entropies_all <- bind_rows(entropies, entropies_child)

ggplot(entropies_all, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper, color = role)) +
  facet_wrap(~ length) + 
  geom_pointrange(position = position_dodge(.25)) +
  geom_smooth(se = F) +
  ggtitle("Adult and Child Unigram Entropy vs. Word Position (German Wagner Corpus with stemming)")
```

```{r Japanese Unigram Entropy}
get_japanese_entropies <- function(role, sen_length, utterances) {
  
  if(role == "Target_Child") {
    sub_utterances <- utterances %>%
      filter(speaker_role == "Target_Child") %>%
      mutate(length = str_count(gloss, " ") + 1) 
  } else {
     sub_utterances <- utterances %>%
      filter(speaker_role != "Target_Child") %>%
      mutate(length = str_count(gloss, " ") + 1)
  }
  
  # 
  # 
  # ggplot(adult_utterances, aes(x = length)) +
  #   geom_histogram(fill = "white", color = "black")
  
  tokens <- sub_utterances %>%
    filter(length == sen_length) %>%
    mutate(utterance_id = 1:n()) %>%
    unnest_tokens(word, gloss) %>%
    group_by(utterance_id) %>%
    mutate(word_order = 1:n())
   
  tokens %>%
    group_by(word_order, word) %>%
    summarise(n = n()) %>%
    tidyboot(summary_function = function(x) x %>% 
               summarise(entropy = entropy.empirical(n, unit = "log2")),
             statistics_functions = function(x) x %>%
             summarise_at(vars(entropy), funs(ci_upper, ci_lower))) %>%
    mutate(role = role, length = sen_length)
}

entropies <- map(2:10, ~get_japanese_entropies("not child", .x, okayama_utterances)) %>%
  bind_rows() %>% filter(word_order <= length) #some utterances have "" counted for word_order

ggplot(entropies, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Adult Unigram Entropy vs. Word Position (Japanese Okayama Corpus)")

entropies_child <- map(2:10, ~ get_japanese_entropies("Target_Child", .x, okayama_utterances)) %>%
  bind_rows() %>% filter(word_order <= length)

ggplot(entropies_child, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Child Unigram Entropy vs. Word Position (Japanese Okayama Corpus)")

entropies_all <- bind_rows(entropies, entropies_child)

ggplot(entropies_all, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper, color = role)) +
  facet_wrap(~ length) + 
  geom_pointrange(position = position_dodge(.25)) +
  geom_smooth(se = F) +
  ggtitle("Adult and Child Unigram Entropy vs. Word Position (Japanese Okayama Corpus)")
```

```{r Chinese Unigram Entropy}
zhou_dinner <- get_utterances(corpus = "zhoudinner")

get_chinese_entropies <- function(role, sen_length, utterances) {
  
  if(role == "Target_Child") {
    sub_utterances <- utterances %>%
      filter(speaker_role == "Target_Child") %>%
      filter(gloss != "") %>% 
      mutate(length = str_count(stem, " ") + 1) 
  } else {
     sub_utterances <- utterances %>%
      filter(speaker_role != "Target_Child") %>%
      filter(speaker_role != "") %>% 
      mutate(length = str_count(stem, " ") + 1)
  }
  
  # 
  # 
  # ggplot(adult_utterances, aes(x = length)) +
  #   geom_histogram(fill = "white", color = "black")
  
  tokens <- sub_utterances %>%
    filter(length == sen_length) %>%
    mutate(utterance_id = 1:n()) %>%
    unnest_tokens(word, stem) %>%
    group_by(utterance_id) %>%
    mutate(word_order = 1:n())
   
  tokens %>%
    group_by(word_order, word) %>%
    summarise(n = n()) %>%
    tidyboot(summary_function = function(x) x %>% 
               summarise(entropy = entropy.empirical(n, unit = "log2")),
             statistics_functions = function(x) x %>%
             summarise_at(vars(entropy), funs(ci_upper, ci_lower))) %>%
    mutate(role = role, length = sen_length)
}

entropies <- map(2:10, ~get_chinese_entropies("not child", .x, zhou_dinner)) %>%
  bind_rows() %>% filter(word_order <= length) #some utterances have "" counted for word_order

ggplot(entropies, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Adult Unigram Entropy vs. Word Position (Mandarin Zhou Dinner Corpus)")

entropies_child <- map(2:10, ~ get_chinese_entropies("Target_Child", .x, zhou_dinner)) %>%
  bind_rows() %>% filter(word_order <= length)

ggplot(entropies_child, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper)) +
  facet_wrap(~ length) + 
  geom_pointrange() +
  geom_smooth(se = F) +
  ggtitle("Child Unigram Entropy vs. Word Position (Mandarin Zhou Dinner Corpus)")

entropies_all <- bind_rows(entropies, entropies_child)

ggplot(entropies_all, aes(x = word_order, y = empirical_entropy,
                      ymin = ci_lower, ymax = ci_upper, color = role)) +
  facet_wrap(~ length) + 
  geom_pointrange(position = position_dodge(.25)) +
  geom_smooth(se = F) +
  ggtitle("Adult and Child Unigram Entropy vs. Word Position (Mandarin Zhou Dinner Corpus)")
```