---
title: By-letter entropy in childes
author: Joe Klafka
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: false
    number_sections: false
    theme: lumen
    toc_float: false
    code_folding: show 
---

```{r setup, include = FALSE}
# load packages
library(knitr)
library(tidyverse)
library(directlabels)
library(childesr) #data
library(SnowballC) #stemmer
library(tidytext)
library(entropy)
library(tidyboot)
library(dplyr)
library(tokenizers)
library(tau)
knitr::opts_chunk$set(echo = TRUE)

opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
               error = FALSE, cache = FALSE, tidy = FALSE)

theme_set(theme_classic(base_size = 16))
```

Get utterances
```{r get_utterances}
prov_utterances <- get_utterances(corpus = "Providence")
```

Compute Providence Corpus Estimates
```{r calc_pos_entropy}
get_counts <- function(role, sen_length, utterances) {
  
  if(role == "Target_Child") {
    sub_utterances <- utterances %>%
      filter(speaker_role == "Target_Child") %>%
      mutate(length = str_count(stem, " ") + 1) # uses stems of words, not original words
  } else {
     sub_utterances <- utterances %>%
      filter(speaker_role != "Target_Child") %>%
      mutate(length = str_count(stem, " ") + 1)
  }
 
  tokens <- sub_utterances %>%
              filter(length == sen_length) %>%
              mutate(utterance_id = 1:n()) %>%
              unnest_tokens(word, stem) %>%
              group_by(utterance_id) %>%
              mutate(word_order = 1:n())
}

get_letters <- function(tokens, word_choice) {
   
  letters <- tokens %>% 
              filter(word_order == word_choice) %>% 
              unnest_tokens(letter, word, token = "characters") %>% 
              group_by(utterance_id) %>% 
              mutate(letter_order = 1:n())
  
  letter_counts <- letters %>% 
                    group_by(letter_order, letter) %>% 
                    summarize(n = n())
  
  map(1:10, ~letter_entropy(letter_counts, .x)) ##first 10 letters, after this entropy shrunk close to 0
}

letter_entropy <- function(letter_counts, position) {
  position_counts <- letter_counts %>% filter(letter_order == position)
  
  entropie <- position_counts$n %>% entropy.empirical(unit = "log2")
}

get_letter_entropies <- function(role, sen_length, utterances) {
  tokens <- get_counts(role, sen_length, utterances)
  map(1:sen_length, ~get_letters(tokens,.x))
}

prov_child_letters <- map(2:10, ~get_letter_entropies("Target_Child", .x, prov_utterances)) #list of lists of lists

#currently have list of lists, where the top list is for a word_order and each bottom list is for a letter_order
```